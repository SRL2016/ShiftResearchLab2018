summarize(n = sum(n))
View(mf.count)
mf.df <- mf.df %>%
anti_join(stop_words)
mf.count <- NULL
mf.count <- mf.df %>%
group_by(manifesto, word) %>%
count() %>%
summarize(n = sum(n))
View(mf.count)
mf.df <- mf.count %>%
bind_tf_idf(word, manifesto, n)
mf.df <-  arrange(mf.df, tf-idf)
mf.df <-  arrange(mf.df, -tf-idf)
View(mf.df)
mf.df <-  arrange(mf.df, -tf_idf)
mf.df <-  arrange(mf.df, -tf_idf)
mf.df[manifesto=="Democratic Party_1960"]
mf.df[, manifesto=="Democratic Party_1960"]
filter(mf.df, manifesto=="Democratic Party_1960")
mf.df <-  arrange(mf.df, -tf_idf)
filter(mf.df, manifesto=="Democratic Party_1960")
filter(mf.df, manifesto=="Republican Party_1960")
filter(mf.df, manifesto=="Democratic Party_2012")
filter(mf.df, manifesto=="Republican Party_2012")
View(manifesto.words)
mf.nrc <- manifesto.words %>%
inner_join(get_sentiments("nrc")) %>%
count(manifesto, sentiment)
View(mf.nrc)
manifesto.words <- unnest_tokens(manifestos, output = word, input = text) %>%
unite(manifesto, partyname, year, sep = "_", remove = FALSE)
word.count <- manifesto.words %>%
group_by(manifesto) %>%
count() %>%
summarize(totalwords = sum(n))
mf.df <- inner_join(manifesto.words, word.count, by = "manifesto")
data("stop_words")
mf.freq <- mf.df %>%
anti_join(stop_words)
mf.count <- mf.freq %>%
group_by(manifesto, word) %>%
count() %>%
summarize(n = sum(n))
mf.freq <- mf.count %>%
bind_tf_idf(word, manifesto, n)
mf.df <-  arrange(mf.df, -tf_idf)
mf.freq <-  arrange(mf.freq, -tf_idf)
filter(mf.freq, manifesto=="Democratic Party_1960")
filter(mf.freq, manifesto=="Republican Party_1960")
filter(mf.freq, manifesto=="Democratic Party_2012")
filter(mf.freq, manifesto=="Republican Party_2012")
mf.nrc <- manifesto.words %>%
inner_join(get_sentiments("nrc")) %>%
count(manifesto, sentiment)
mf.nrc <- mf.df %>%
inner_join(get_sentiments("nrc")) %>%
count(manifesto, sentiment)
View(mf.df)
View(mf.count)
View(word.count)
mf.nrc <- mf.df %>%
inner_join(get_sentiments("nrc")) %>%
count(manifesto, sentiment, wt=1/totalwords) %>%
inner_join(word.count, by = "manifesto")
View(manifestos)
mf.sent <- inner_join(mf.nrc, manifestos, by = "manifesto")
manifestos <- unite(manifestos, manifesto, partyname, year, sep = "_", remove = FALSE)
mf.sent <- inner_join(mf.nrc, manifestos, by = "manifesto")
View(mf.sent)
g <- ggplot(mf.sent, aes(x = proportion, y = presvote, colour=sentiment)) +
geom_point() +
geom_smooth(method="lm", se = FALSE) +
labs(x = "Proportion", y =  "Presidential Vote Share") +
facet_wrap(~sentiment, ncol = 2, scales = "free") +
coord_flip()
g
g <- ggplot(mf.sent, aes(x = n, y = presvote, colour=sentiment)) +
geom_point() +
geom_smooth(method="lm", se = FALSE) +
labs(x = "Proportion", y =  "Presidential Vote Share") +
facet_wrap(~sentiment, ncol = 2, scales = "free") +
coord_flip()
g
g <- ggplot(mf.sent, aes(x = n, y = presvote, colour=sentiment)) +
geom_point() +
geom_smooth(method="lm", se = FALSE) +
labs(x = "Proportion", y =  "Presidential Vote Share") +
facet_wrap(~sentiment, ncol = 2, scales = "free") +
coord_flip()
g
g <- ggplot(mf.sent, aes(x = n, y = presvote, colour=sentiment)) +
geom_point() +
geom_smooth(method="lm", se = FALSE) +
labs(x = "Proportion", y =  "Presidential Vote Share") +
facet_wrap(~sentiment, ncol = 2, scales = "free") +
coord_flip()
g
library(manifestoR)
mp_setapikey(key = API)
data <- mp_maindataset()
data <- filter(data, countryname == "United States")
data <- mutate(data, year = lubridate::year(edate))
data <- filter(data, year >=1960)
mpc <- mp_corpus(data, codefilter = NULL)
text <- sapply(mpc, FUN=function(x){
paste(x$content$text, collapse=" ")
})
manifestos <- data.frame(text = text,
year = c(1960, 1960, 1964, 1964, 1968,
1968, 1972, 1972, 1976, 1976,
1980, 1980, 1984, 1984, 1988,
1988, 1992, 1992, 1996, 1996,
2000, 2000, 2004, 2004, 2008,
2008, 2012, 2012),
partyname = rep(c("Democratic Party",
"Republican Party"), 14),
stringsAsFactors = FALSE)
rownames(manifestos) <- NULL
data <- dplyr::select(data, partyname, year, presvote)
manifestos <- full_join(manifestos, data)
manifestos$presvote[manifestos$year==2008 & manifestos$partyname == "Democratic Party"] <- 52.9
manifestos$presvote[manifestos$year==2008 & manifestos$partyname == "Republican Party"] <- 45.7
manifesto.words <- unnest_tokens(manifestos, output = word, input = text) %>%
unite(manifesto, partyname, year, sep = "_", remove = FALSE)
word.count <- manifesto.words %>%
group_by(manifesto) %>%
count() %>%
summarize(totalwords = sum(n))
mf.df <- inner_join(manifesto.words, word.count, by = "manifesto")
knitr::opts_chunk$set(echo = TRUE)
library(stargazer)
quantile(happy$medianage, .1, .3, .65, .91286)
knitr::opts_chunk$set(echo = TRUE)
library(stargazer)
library(knitr)
library(tidyverse)
library(tidytext)
library(margins)
oil.religion <- read_csv("oilreligion.csv")
happy <- read_csv("happy.csv", skip = 2) # header text
dim(oil.religion) # 253 rows, 3 columns
dim(happy) # 156 rows, 11 columns
happy <- select(happy, `Country`, `Happiness score`)
happy <- rename(happy, happy.score=`Happiness score`, country=Country)
oil.religion <- rename(oil.religion, religion=`I_RELIGION`, country=icountry)
oil.religion <- mutate(oil.religion, religion = as.factor(religion),
oilstate = as.factor(oilstate))
oil.religion <- mutate(oil.religion, religion=fct_recode(religion, NULL = "-999"),
oilstate=fct_recode(oilstate,
"oil-exporting"="1",
"non-oil-exporting"="0",
NULL = "-999"))
happy <- arrange(happy, happy.score)
kable(head(happy, 10), col.names = c("Country", "Happiness Score"))
happy <- arrange(happy, -happy.score)
kable(head(happy, 10), col.names = c("Country", "Happiness Score"))
intersect(names(happy), names(oil.religion))
unique.happy <- unique(select(happy, country))
nrow(unique.happy) # 156 rows
nrow(happy) # 156 rows
unique.oilrelig <- unique(select(oil.religion, country))
nrow(unique.oilrelig) # 253 rows
nrow(oil.religion) #253 rows
# countries in happy but not oil.religion
check1 <- anti_join(happy, oil.religion, by=c("country"))
# countries in oil.religion but not happy
check2 <- anti_join(oil.religion, happy, by=c("country"))
kable(check1)
# kable(check2) commented out because it takes up a ton of space in the markdown
oil.religion <- oil.religion %>%
mutate(country = fct_recode(country,
"United States" = "USA",
"United Kingdom" = "UK",
"United Arab Emirates" = "UAE",
"Taiwan Province of China" = "Taiwan",
"Trinidad & Tobago" = "Trinidad and Tobago",
"Hong Kong SAR, China" = "Hong Kong",
"Palestinian Territories" = "Palestine (Israeli Occupied Territories)",
"Ivory Coast" = "Cote d'Ivoire",
"Congo (Brazzaville)" = "Congo, Republic of the",
"Myanmar" = "Burma (Myanmar)",
"Congo (Kinshasa)" = "Congo, Democratic Republic of the"))
# check to see I didn't make any mistakes
check1 <- anti_join(happy, oil.religion, by=c("country"))
check2 <- anti_join(oil.religion, happy, by=c("country"))
kable(check1) # No match for South Sudan from the happy data in the oil.religion data
# probably because it's a new country??
# kable(check2)
happy <- inner_join(happy, oil.religion, by="country")
un <- read_csv("unindicators.csv")
un <- gather(un, Afghanistan:Zimbabwe, key="country", value="value")
un <- spread(un, var, value)
un <- mutate(un,
region=fct_recode(region,
"Asia/Oceania" = "Australia/New Zealand/Oceania",
"Asia/Oceania" = "Asia",
"Americas" = "Latin America/Caribbean",
"Americas" = "USA/Canada"))
# ID NAMES CHECK
intersect(names(happy), names(un)) # only shared variable name is country
# UNIQUE ID CHECK
unique.happy <- unique(select(happy, country))
nrow(unique.happy) # 156 rows
nrow(happy) # 156 rows
unique.un <- unique(select(un, country))
nrow(unique.un) # 253 rows
nrow(un) # 253 rows
# countries in happy but not oil.religion
check1 <- anti_join(happy, un, by=c("country"))
# countries in oil.religion but not happy
check2 <- anti_join(un, happy, by=c("country"))
kable(check1)
# kable(check2) # commented out because it takes up a lot of space in the markdown
un <- un %>%
mutate(country = fct_recode(country,
"Taiwan Province of China" = "Taiwan",
"Trinidad & Tobago" = "Trinidad and Tobago",
"Hong Kong SAR, China" = "Hong Kong",
"South Korea" = "Korea, South",
"Palestinian Territories" = "Palestine (Israeli Occupied Territories)",
"Ivory Coast" = "Cote d'Ivoire",
"Congo (Brazzaville)" = "Congo, Republic of the",
"Myanmar" = "Burma (Myanmar)",
"Congo (Kinshasa)" = "Congo, Democratic Republic of the"))
# check to see I didn't make any mistakes
check1 <- anti_join(happy, un, by=c("country"))
check2 <- anti_join(un, happy, by=c("country"))
happy <- inner_join(happy, un, by="country")
str(happy)
happy <- happy %>%
mutate(
gdpcap = as.numeric(gdpcap),
GINI = as.numeric(GINI),
literacy = as.numeric(literacy),
medianage = as.numeric(medianage),
population = as.numeric(population),
population = population/1000000,
povertyindex = as.numeric(povertyindex),
povertyindex = 100*povertyindex,
happy.bin = ifelse(happy.score>4.5, TRUE, FALSE))
quantile(happy$medianage, probs=c(.1, .3, .65, .91286), na.rm=TRUE)
levels(happy$oilstate)
t.test(happy.score ~ oilstate, data=happy)
levels(happy$oilstate)
install.packages("tidyverse")
install.packages("forcats")
install.packages("dplyr")
install.packages("tidyr")
install.packages("lubridate")
install.packages("stringr")
install.packages("chorddiag")
install.packages("chorddiag")
install.packages("htmlwidgets")
install.packages("chorddiag")
devtools::install_github("rstudio/r2d3")
install.packages("devtools")
## C. McClintock
## Shift Research Lab
## Summer 2018 ## Updated: May 22, 2018
## Cleaning Script: Bureau of Labor Statistics Occupational Data
# ..................................................................................................
# set up: wd, retrieve encrypted data
rm(list=ls())
getwd()
# if need be setwd("~/../../")
setwd("R/ShiftResearchLab2018/data-bls")
# set up: libraries
library(dplyr)
library(forcats)
library(tidyverse)
library(readxl)
library(tidyr)
# ..................................................................................................
# read in the data
bls <- read_excel("MSA_M2017_dl.xlsx")
# make the variable names lower case
names(bls)
names(bls) <- tolower(names(bls))
bls <- rename(bls, "loc_quotient"="loc quotient")
# select only the denver region data
bls <- filter(bls, area_name=="Denver-Aurora-Lakewood, CO")
# recode asterisk values as NA
bls[bls=="*"] <- NA # code book says "* = indicates that a wage estimate is not available"
# recode hashtag values as 208,000
bls[bls=="#"] <- 208000 # code book says "# = indicates a wage that is equal to or greater than $100.00 per hour or $208,000 per year"
# NOTE: this is a lower limit
# quick overviews
dim(bls)
summary(bls)
str(bls)
# coerce to numeric class
bls[,6:23] <- lapply(bls[,6:23], as.numeric)
# split occupational code at -
bls <- separate(bls, occ_code, c("occ_code1", "occ_code2"), sep = "-")
# subset of generalized professions
bls.gen <- filter(bls, occ_code2=="0000") # seem to all end occ_code in "0000"
bls.gen <- filter(bls.gen, !occ_title=="All Occupations") # remove the occupational sum
View(bls)
View(bls.gen)
## C. McClintock
## Shift Research Lab
## Summer 2018 ## Updated: May 22, 2018
## Cleaning Script: Bureau of Labor Statistics Occupational Data
# ..................................................................................................
# set up: wd, retrieve encrypted data
rm(list=ls())
getwd()
# if need be setwd("~/../../")
setwd("R/ShiftResearchLab2018/data-bls")
# set up: libraries
library(dplyr)
library(forcats)
library(tidyverse)
library(readxl)
library(tidyr)
# ..................................................................................................
# read in the data
bls <- read_excel("MSA_M2017_dl.xlsx")
# make the variable names lower case
names(bls)
names(bls) <- tolower(names(bls))
bls <- rename(bls, "loc_quotient"="loc quotient")
# select only the denver region data
bls <- filter(bls, area_name=="Denver-Aurora-Lakewood, CO")
# recode asterisk values as NA
bls[bls=="*"] <- NA # code book says "* = indicates that a wage estimate is not available"
# recode hashtag values as 208,000
bls[bls=="#"] <- 208000 # code book says "# = indicates a wage that is equal to or greater than $100.00 per hour or $208,000 per year"
# NOTE: this is a lower limit
# quick overviews
dim(bls)
summary(bls)
str(bls)
# coerce to numeric class
bls[,6:23] <- lapply(bls[,6:23], as.numeric)
# split occupational code at -
bls <- separate(bls, occ_code, c("occ_code1", "occ_code2"), sep = "-")
# subset of generalized professions
bls.gen <- filter(bls, occ_code2=="0000") # seem to all end occ_code in "0000"
bls.gen <- filter(bls.gen, !occ_title=="All Occupations") # remove the occupational sum
# subset of specific professions
bls.spec <- filter(bls, !occ_code2=="0000") # all except general
# the value summary for all occupations
bls.all <- filter(bls, occ_title=="All Occupations")
sum(bls.spec$jobs_1000, na.rm=TRUE) # 976.82 # what's missing? # 23.16
sum(bls.gen$jobs_1000) # 999.99 # good
# check to see if occ_code1 matches 1-1 to general occupations
n_distinct(bls.spec$occ_code1) # 22
nrow(bls.gen) # 22
# add a variable to account for spread
bls.gen <- mutate(bls.gen,
quartilespread = a_pct75-a_pct25)
bls.spec <- mutate(bls.spec,
quartilespread = a_pct75-a_pct25)
# what's the relationship between median annual wage and quartile spread?
ggplot(bls.gen, aes(a_median, quartilespread)) + geom_point() + geom_smooth(method="lm", se = FALSE)
ggplot(bls.spec, aes(a_median, quartilespread)) + geom_point() + geom_smooth(method="lm", se = FALSE)
# ..................................................................................................
# write objects as clean csv files
write.csv(bls.gen, "clean.bls.gen.csv")
write.csv(bls.spec, "clean.bls.spec.csv")
View(bls.spec)
View(bls.gen)
View(bls.gen)
bls.ind <- select(bls.gen, occ_code1, occ_title)
bls.ind <- rename(bls.ind, "industry"="occ_title")
View(bls.ind)
bls.spec <- left_join(bls.spec, bls.ind, by=occ_code1)
View(bls.spec)
View(bls.ind)
bls.spec <- left_join(bls.spec, bls.ind, by="occ_code1")
View(bls.spec)
## C. McClintock
## Shift Research Lab
## Summer 2018 ## Updated: May 22, 2018
## Cleaning Script: Bureau of Labor Statistics Occupational Data
# ..................................................................................................
# set up: wd, retrieve encrypted data
rm(list=ls())
getwd()
# if need be setwd("~/../../")
setwd("R/ShiftResearchLab2018/data-bls")
# set up: libraries
library(dplyr)
library(forcats)
library(tidyverse)
library(readxl)
library(tidyr)
# ..................................................................................................
# read in the data
bls <- read_excel("MSA_M2017_dl.xlsx")
# make the variable names lower case
names(bls)
names(bls) <- tolower(names(bls))
bls <- rename(bls, "loc_quotient"="loc quotient")
# select only the denver region data
bls <- filter(bls, area_name=="Denver-Aurora-Lakewood, CO")
# recode asterisk values as NA
bls[bls=="*"] <- NA # code book says "* = indicates that a wage estimate is not available"
# recode hashtag values as 208,000
bls[bls=="#"] <- 208000 # code book says "# = indicates a wage that is equal to or greater than $100.00 per hour or $208,000 per year"
# NOTE: this is a lower limit
# quick overviews
dim(bls)
summary(bls)
str(bls)
# coerce to numeric class
bls[,6:23] <- lapply(bls[,6:23], as.numeric)
# split occupational code at -
bls <- separate(bls, occ_code, c("occ_code1", "occ_code2"), sep = "-")
# subset of generalized professions
bls.gen <- filter(bls, occ_code2=="0000") # seem to all end occ_code in "0000"
bls.gen <- filter(bls.gen, !occ_title=="All Occupations") # remove the occupational sum
# subset of specific professions
bls.spec <- filter(bls, !occ_code2=="0000") # all except general
# the value summary for all occupations
bls.all <- filter(bls, occ_title=="All Occupations")
sum(bls.spec$jobs_1000, na.rm=TRUE) # 976.82 # what's missing? # 23.16
sum(bls.gen$jobs_1000) # 999.99 # good
# check to see if occ_code1 matches 1-1 to general occupations
n_distinct(bls.spec$occ_code1) # 22
nrow(bls.gen) # 22
# ..................................................................................................
# add a variable to account for spread
bls.gen <- mutate(bls.gen,
quartilespread = a_pct75-a_pct25)
bls.spec <- mutate(bls.spec,
quartilespread = a_pct75-a_pct25)
# what's the relationship between median annual wage and quartile spread?
ggplot(bls.gen, aes(a_median, quartilespread)) + geom_point() + geom_smooth(method="lm", se = FALSE)
ggplot(bls.spec, aes(a_median, quartilespread)) + geom_point() + geom_smooth(method="lm", se = FALSE)
# ..................................................................................................
# add gen to spec to get an industry variable
bls.ind <- select(bls.gen, occ_code1, occ_title)
bls.ind <- rename(bls.ind, "industry"="occ_title")
bls.spec <- left_join(bls.spec, bls.ind, by="occ_code1")
# ..................................................................................................
# write objects as clean csv files
write.csv(bls.gen, "clean.bls.gen.csv")
write.csv(bls.spec, "clean.bls.spec.csv")
install.packages("plotly")
install.packages("shiny")
## C. McClintock
## Shift Research Lab
## Summer 2018 ## Updated: May 22, 2018
## Cleaning Script: Bureau of Labor Statistics Occupational Data
# ..................................................................................................
# set up: wd, retrieve encrypted data
rm(list=ls())
getwd()
# if need be setwd("~/../../")
setwd("R/ShiftResearchLab2018/data-bls")
# set up: libraries
library(dplyr)
library(forcats)
library(tidyverse)
library(readxl)
library(tidyr)
# ..................................................................................................
# read in the data
bls <- read_excel("MSA_M2017_dl.xlsx")
# make the variable names lower case
names(bls)
names(bls) <- tolower(names(bls))
bls <- rename(bls, "loc_quotient"="loc quotient")
# select only the denver region data
bls <- filter(bls, area_name=="Denver-Aurora-Lakewood, CO")
# recode asterisk values as NA
bls[bls=="*"] <- NA # code book says "* = indicates that a wage estimate is not available"
# recode hashtag values as 208,000
bls[bls=="#"] <- 208000 # code book says "# = indicates a wage that is equal to or greater than $100.00 per hour or $208,000 per year"
# NOTE: this is a lower limit
# quick overviews
dim(bls)
summary(bls)
str(bls)
# coerce to numeric class
bls[,6:23] <- lapply(bls[,6:23], as.numeric)
# split occupational code at -
bls <- separate(bls, occ_code, c("occ_code1", "occ_code2"), sep = "-")
# subset of generalized professions
bls.gen <- filter(bls, occ_code2=="0000") # seem to all end occ_code in "0000"
bls.gen <- filter(bls.gen, !occ_title=="All Occupations") # remove the occupational sum
# subset of specific professions
bls.spec <- filter(bls, !occ_code2=="0000") # all except general
# the value summary for all occupations
bls.all <- filter(bls, occ_title=="All Occupations")
sum(bls.spec$jobs_1000, na.rm=TRUE) # 976.82 # what's missing? # 23.16
sum(bls.gen$jobs_1000) # 999.99 # good
# check to see if occ_code1 matches 1-1 to general occupations
n_distinct(bls.spec$occ_code1) # 22
nrow(bls.gen) # 22
# ..................................................................................................
# add a variable to account for spread
bls.gen <- mutate(bls.gen,
quartilespread = a_pct75-a_pct25)
bls.spec <- mutate(bls.spec,
quartilespread = a_pct75-a_pct25)
# what's the relationship between median annual wage and quartile spread?
ggplot(bls.gen, aes(a_median, quartilespread)) + geom_point() + geom_smooth(method="lm", se = FALSE)
ggplot(bls.spec, aes(a_median, quartilespread)) + geom_point() + geom_smooth(method="lm", se = FALSE)
# ..................................................................................................
# add gen to spec to get an industry variable
bls.ind <- select(bls.gen, occ_code1, occ_title)
bls.ind <- rename(bls.ind, "industry"="occ_title")
bls.spec <- left_join(bls.spec, bls.ind, by="occ_code1")
save.image("wages.Rdata")
# ..................................................................................................
# write objects as clean csv files
write.csv(bls.gen, "clean.bls.gen.csv")
write.csv(bls.spec, "clean.bls.spec.csv")
