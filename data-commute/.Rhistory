inputId = "industry",
label = "Industry:",
choices = as.character(unique(bls.spec$industry)),
selected = "Management Occupations")
})
output$occupation_selector <- renderUI({
available <- bls.spec[bls.spec$industry == input$industry, "occ_title"]
selectInput(
inputId = "occupation",
label = "Occupation:",
choices = unique(available),
selected = unique(available)[1])
})
})
##
shinyApp(ui = ui, server = server)
ui <- shinyUI(fluidPage(
titlePanel("Housing Affordability Tool"),
sidebarPanel(
htmlOutput("industry_selector"),
htmlOutput("occupation_selector")
),
mainPanel(plotlyOutput("plot"))
))
server <- shinyServer(function(input, output) {
output$plot <- renderPlotly({
plot_ly(data = subset(data, data$occupation==input$occupation), x = ~schoolquality, y = ~affordability, type = 'scatter', mode = 'markers',
color = ~avgcommute, colors = 'Blues', marker =
list(size = ~avgcommute, opacity = 0.5), hoverinfo = 'text',
text = ~paste('Neighborhood:', nbhd, '<br>Percent Affordable Housing', affordability,  '<br>School Quality (Percentile):',
schoolquality)) %>%
layout(title = 'Housing Affordability and School Quality by Occupation',
xaxis = list(title = 'School Quality',
gridcolor = 'rgb(255, 255, 255)',
zerolinewidth = 1,
ticklen = 5,
gridwidth = 2),
yaxis = list(title = 'Percent Affordable Housing',
gridcolor = 'rgb(255, 255, 255)',
zerolinewidth = 1,
ticklen = 5,
gridwidth = 2),
paper_bgcolor = 'rgb(243, 243, 243)',
plot_bgcolor = 'rgb(243, 243, 243)')
})
output$industry_selector <- renderUI({
selectInput(
inputId = "industry",
label = "Industry:",
choices = as.character(unique(bls.spec$industry)),
selected = "Management Occupations")
})
output$occupation_selector <- renderUI({
available <- bls.spec[bls.spec$industry == input$industry, "occ_title"]
selectInput(
inputId = "occupation",
label = "Occupation:",
choices = unique(available),
selected = unique(available)[1])
})
})
##
shinyApp(ui = ui, server = server)
## C. McClintock
## Shift Research Lab
## Summer 2018 ## Updated: May 22, 2018
## Cleaning Script: ACS 5-year Commute Data
# ..................................................................................................
# set up: wd, retrieve encrypted data
rm(list=ls())
getwd()
# if need be setwd("~/../../")
setwd("R/ShiftResearchLab2018/data-commute")
# set up: libraries
library(dplyr)
library(forcats)
library(tidyverse)
library(readxl)
library(tidyr)
# ..................................................................................................
# AVERAGE COMMUTE TIME
# read in the average commute time data (ACS 2016)
avg <- read_csv("avg.commute.csv")
# select just the first row
avg <- avg[1,]
# move columns to rows
avg <- gather(avg, tract, avgcommute, 2:ncol(avg))
avg <- select(avg, -X1)
# ..................................................................................................
# TRAVEL TIME DISTRIBUTIONS
# read in commute distributions (ACS 2016)
travel <- read_csv("traveltime.csv")
travel <- travel[1:10,] # select rows with values
# reshape the data to be useful
travel <- gather(travel, tract, n, 2:ncol(travel))
travel <- spread(travel, X1, n)
# rename the variables for ease of use
names(travel)
names(travel) <- c("tract", "10to19", "20to29", "30to39", "40to59",
"60to89", "90plus", "total_outside", "less10",
"workedhome", "total")
# reorder the columns
travel <- select(travel, tract, less10, everything())
# merge the data
commute <- left_join(travel, avg, by="tract")
# read in the tract information
info <- read_csv("acs.meta.csv")
info <- select(info, Geo_FIPS, Geo_NAME, Geo_TRACT)
names(info) <- c("geo_id", "tract", "tract_num")
# merge with commute info
commute <- left_join(info, commute, by="tract")
# ..................................................................................................
# MATCHING TRACTS TO NEIGHBORHOODS
# read in matching tracts data
match <- read_csv("matchingtracts.csv")
match <- rename(match, "geo_id"="geoid10")
# merge with commute data
nbhd <- full_join(match, commute, by="geo_id")
# break up the big tract variable
nbhd <- separate(nbhd, tract, c("tract", "county", "state"), sep = ",")
nbhd <- select(nbhd, -c(tract, state))
n_distinct(nbhd$nhid) # 265
n_distinct(nbhd$nhname) # 264 # why is this one less?
# n occurences of each neighborhood name
nhname.freq <- nbhd %>%
count(nhname) # 576 NAs, tracts that don't match a neighborhood
# n occurences of each neighborhood id
nhid.freq <- nbhd %>%
count(nhid) # 576 NAs, tracts that don't match a neighborhood
arb <- filter(nbhd, is.na(nhname)&!is.na(nhid)) # no values so nhname is not blank
str(nbhd) # check the class of the variables
nbhd$avgcommute <- as.numeric(nbhd$avgcommute) # coerce avg commute to numeric class
nbhd$nhid <- as.numeric(nbhd$nhid)
# what's the average denver metro commute time?
mean(nbhd$avgcommute, na.rm=TRUE) # 26.57
median(nbhd$avgcommute, na.rm = TRUE) # 26
# compute neighborhood average commute time
nbhd.avg <- aggregate(nbhd$avgcommute,by=list(name=nbhd$nhname, nhid=nbhd$nhid), data=nbhd, FUN=mean)
nbhd.avg <- rename(nbhd.avg, "avgcommute"="x")
nrow(nbhd.avg) # 264
# 7 NA values, why?
na.check <- filter(nbhd.avg, is.na(avgcommute))
# check with NAs in avg commute removed
nbhd2 <- filter(nbhd, !is.na(nbhd$avgcommute)) # remove observations with NA in avg commute
nbhd.avg2 <- aggregate(nbhd2$avgcommute,by=list(name=nbhd2$nhname, nhid=nbhd2$nhid), data=nbhd2, FUN=mean)
nbhd.avg2 <- rename(nbhd.avg2, "avgcommute"="x")
nrow(nbhd.avg2) # 262 # 2 missing
# check which two are missing
arb <- anti_join(nbhd.avg, nbhd.avg2, by="name")
# Federal Center # Rocky Mountain Arsenal
# one tract each with a missing avg commute and missing travel time, will be excluded
# rename for ease of use
avgcmt <- nbhd.avg2
# number of distinct neighborhoods
n_distinct(avgcmt$name) # 261
# ..................................................................................................
# ADD SOME POTENTIALLY USEFUL MEASURES
mean(avgcmt$avgcommute) # 26.47
avgcmt <- mutate(avgcmt, # difference between nbhd and avg
meandelta=avgcommute-mean(avgcmt$avgcommute))
# ..................................................................................................
# write the object as a csv for later use
write.csv(nbhd, "clean.nbhdcommutes.csv")
write.csv(avgcmt, "clean.avgcommute.csv")
rm(list = ls(pattern = "arb"))
rm(list = ls(pattern = "avg"))
rm(list = ls(pattern = "commute"))
rm(list = ls(pattern = "info"))
rm(list = ls(pattern = "match"))
rm(list = ls(pattern = "nbhd"))
rm(list = ls(pattern = "nh"))
rm(list = ls(pattern = "travel"))
## C. McClintock
## Shift Research Lab
## Summer 2018 ## Updated: May 22, 2018
## Cleaning Script: ACS 5-year Commute Data
# ..................................................................................................
# set up: wd, retrieve encrypted data
rm(list=ls())
getwd()
# if need be setwd("~/../../")
setwd("R/ShiftResearchLab2018/data-commute")
# set up: libraries
library(dplyr)
library(forcats)
library(tidyverse)
library(readxl)
library(tidyr)
# ..................................................................................................
# AVERAGE COMMUTE TIME
# read in the average commute time data (ACS 2016)
avg <- read_csv("avg.commute.csv")
# select just the first row
avg <- avg[1,]
# move columns to rows
avg <- gather(avg, tract, avgcommute, 2:ncol(avg))
avg <- select(avg, -X1)
# ..................................................................................................
# TRAVEL TIME DISTRIBUTIONS
# read in commute distributions (ACS 2016)
travel <- read_csv("traveltime.csv")
travel <- travel[1:10,] # select rows with values
# reshape the data to be useful
travel <- gather(travel, tract, n, 2:ncol(travel))
travel <- spread(travel, X1, n)
# rename the variables for ease of use
names(travel)
names(travel) <- c("tract", "10to19", "20to29", "30to39", "40to59",
"60to89", "90plus", "total_outside", "less10",
"workedhome", "total")
# reorder the columns
travel <- select(travel, tract, less10, everything())
# merge the data
commute <- left_join(travel, avg, by="tract")
# read in the tract information
info <- read_csv("acs.meta.csv")
info <- select(info, Geo_FIPS, Geo_NAME, Geo_TRACT)
names(info) <- c("geo_id", "tract", "tract_num")
# merge with commute info
commute <- left_join(info, commute, by="tract")
# ..................................................................................................
# MATCHING TRACTS TO NEIGHBORHOODS
# read in matching tracts data
match <- read_csv("matchingtracts.csv")
match <- rename(match, "geo_id"="geoid10")
# merge with commute data
nbhd <- full_join(match, commute, by="geo_id")
# break up the big tract variable
nbhd <- separate(nbhd, tract, c("tract", "county", "state"), sep = ",")
nbhd <- select(nbhd, -c(tract, state))
n_distinct(nbhd$nhid) # 265
n_distinct(nbhd$nhname) # 264 # why is this one less?
# n occurences of each neighborhood name
nhname.freq <- nbhd %>%
count(nhname) # 576 NAs, tracts that don't match a neighborhood
# n occurences of each neighborhood id
nhid.freq <- nbhd %>%
count(nhid) # 576 NAs, tracts that don't match a neighborhood
arb <- filter(nbhd, is.na(nhname)&!is.na(nhid)) # no values so nhname is not blank
str(nbhd) # check the class of the variables
nbhd$avgcommute <- as.numeric(nbhd$avgcommute) # coerce avg commute to numeric class
nbhd$nhid <- as.numeric(nbhd$nhid)
# what's the average denver metro commute time?
mean(nbhd$avgcommute, na.rm=TRUE) # 26.57
median(nbhd$avgcommute, na.rm = TRUE) # 26
# compute neighborhood average commute time
nbhd.avg <- aggregate(nbhd$avgcommute,by=list(name=nbhd$nhname, nhid=nbhd$nhid), data=nbhd, FUN=mean)
nbhd.avg <- rename(nbhd.avg, "avgcommute"="x")
nrow(nbhd.avg) # 264
# 7 NA values, why?
na.check <- filter(nbhd.avg, is.na(avgcommute))
# check with NAs in avg commute removed
nbhd2 <- filter(nbhd, !is.na(nbhd$avgcommute)) # remove observations with NA in avg commute
nbhd.avg2 <- aggregate(nbhd2$avgcommute,by=list(name=nbhd2$nhname, nhid=nbhd2$nhid), data=nbhd2, FUN=mean)
nbhd.avg2 <- rename(nbhd.avg2, "avgcommute"="x")
nrow(nbhd.avg2) # 262 # 2 missing
# check which two are missing
arb <- anti_join(nbhd.avg, nbhd.avg2, by="name")
# Federal Center # Rocky Mountain Arsenal
# one tract each with a missing avg commute and missing travel time, will be excluded
# rename for ease of use
avgcmt <- nbhd.avg2
# number of distinct neighborhoods
n_distinct(avgcmt$name) # 261
# ..................................................................................................
# ADD SOME POTENTIALLY USEFUL MEASURES
mean(avgcmt$avgcommute) # 26.47
avgcmt <- mutate(avgcmt, # difference between nbhd and avg
meandelta=avgcommute-mean(avgcmt$avgcommute))
# ..................................................................................................
# write the object as a csv for later use
write.csv(nbhd, "clean.nbhdcommutes.csv")
write.csv(avgcmt, "clean.avgcommute.csv")
rm(list = ls(pattern = "arb"))
rm(list = ls(pattern = "avgcmt"))
rm(list = ls(pattern = "commute"))
rm(list = ls(pattern = "info"))
rm(list = ls(pattern = "match"))
rm(list = ls(pattern = "nbhd"))
rm(list = ls(pattern = "nh"))
rm(list = ls(pattern = "travel"))
rm(list = ls(pattern = "na.check"))
save.image("commute.Rdata")
# ..................................................................................................
# TO DO LIST:
# figure out why there are 265 nhids and 264 nhnames
## C. McClintock
## Shift Research Lab
## Summer 2018 ## Updated: May 22, 2018
## Cleaning Script: ACS 5-year Commute Data
# ..................................................................................................
# set up: wd, retrieve encrypted data
rm(list=ls())
getwd()
# if need be setwd("~/../../")
setwd("R/ShiftResearchLab2018/data-commute")
# set up: libraries
library(dplyr)
library(forcats)
library(tidyverse)
library(readxl)
library(tidyr)
# ..................................................................................................
# AVERAGE COMMUTE TIME
# read in the average commute time data (ACS 2016)
avg <- read_csv("avg.commute.csv")
# select just the first row
avg <- avg[1,]
# move columns to rows
avg <- gather(avg, tract, avgcommute, 2:ncol(avg))
avg <- select(avg, -X1)
# ..................................................................................................
# TRAVEL TIME DISTRIBUTIONS
# read in commute distributions (ACS 2016)
travel <- read_csv("traveltime.csv")
travel <- travel[1:10,] # select rows with values
# reshape the data to be useful
travel <- gather(travel, tract, n, 2:ncol(travel))
travel <- spread(travel, X1, n)
# rename the variables for ease of use
names(travel)
names(travel) <- c("tract", "10to19", "20to29", "30to39", "40to59",
"60to89", "90plus", "total_outside", "less10",
"workedhome", "total")
# reorder the columns
travel <- select(travel, tract, less10, everything())
# merge the data
commute <- left_join(travel, avg, by="tract")
# read in the tract information
info <- read_csv("acs.meta.csv")
info <- select(info, Geo_FIPS, Geo_NAME, Geo_TRACT)
names(info) <- c("geo_id", "tract", "tract_num")
# merge with commute info
commute <- left_join(info, commute, by="tract")
# ..................................................................................................
# MATCHING TRACTS TO NEIGHBORHOODS
# read in matching tracts data
match <- read_csv("matchingtracts.csv")
match <- rename(match, "geo_id"="geoid10")
# merge with commute data
nbhd <- full_join(match, commute, by="geo_id")
# break up the big tract variable
nbhd <- separate(nbhd, tract, c("tract", "county", "state"), sep = ",")
nbhd <- select(nbhd, -c(tract, state))
n_distinct(nbhd$nhid) # 265
n_distinct(nbhd$nhname) # 264 # why is this one less?
# n occurences of each neighborhood name
nhname.freq <- nbhd %>%
count(nhname) # 576 NAs, tracts that don't match a neighborhood
# n occurences of each neighborhood id
nhid.freq <- nbhd %>%
count(nhid) # 576 NAs, tracts that don't match a neighborhood
arb <- filter(nbhd, is.na(nhname)&!is.na(nhid)) # no values so nhname is not blank
str(nbhd) # check the class of the variables
nbhd$avgcommute <- as.numeric(nbhd$avgcommute) # coerce avg commute to numeric class
nbhd$nhid <- as.numeric(nbhd$nhid)
# what's the average denver metro commute time?
mean(nbhd$avgcommute, na.rm=TRUE) # 26.57
median(nbhd$avgcommute, na.rm = TRUE) # 26
# compute neighborhood average commute time
nbhd.avg <- aggregate(nbhd$avgcommute,by=list(name=nbhd$nhname, nhid=nbhd$nhid), data=nbhd, FUN=mean)
nbhd.avg <- rename(nbhd.avg, "avgcommute"="x")
nrow(nbhd.avg) # 264
# 7 NA values, why?
na.check <- filter(nbhd.avg, is.na(avgcommute))
# check with NAs in avg commute removed
nbhd2 <- filter(nbhd, !is.na(nbhd$avgcommute)) # remove observations with NA in avg commute
nbhd.avg2 <- aggregate(nbhd2$avgcommute,by=list(name=nbhd2$nhname, nhid=nbhd2$nhid), data=nbhd2, FUN=mean)
nbhd.avg2 <- rename(nbhd.avg2, "avgcommute"="x")
nrow(nbhd.avg2) # 262 # 2 missing
# check which two are missing
arb <- anti_join(nbhd.avg, nbhd.avg2, by="name")
# Federal Center # Rocky Mountain Arsenal
# one tract each with a missing avg commute and missing travel time, will be excluded
# rename for ease of use
avgcmt <- nbhd.avg2
# number of distinct neighborhoods
n_distinct(avgcmt$name) # 261
# ..................................................................................................
# ADD SOME POTENTIALLY USEFUL MEASURES
mean(avgcmt$avgcommute) # 26.47
avgcmt <- mutate(avgcmt, # difference between nbhd and avg
meandelta=avgcommute-mean(avgcmt$avgcommute))
# ..................................................................................................
# write the object as a csv for later use
write.csv(nbhd, "clean.nbhdcommutes.csv")
write.csv(avgcmt, "clean.avgcommute.csv")
rm(list = ls(pattern = "arb"))
rm(list = ls(pattern = "commute"))
rm(list = ls(pattern = "info"))
rm(list = ls(pattern = "match"))
rm(list = ls(pattern = "nbhd"))
rm(list = ls(pattern = "nh"))
rm(list = ls(pattern = "travel"))
rm(list = ls(pattern = "na.check"))
save.image("commute.Rdata")
# ..................................................................................................
# TO DO LIST:
# figure out why there are 265 nhids and 264 nhnames
## C. McClintock
## Shift Research Lab
## Summer 2018 ## Updated: May 22, 2018
## Cleaning Script: ACS 5-year Commute Data
# ..................................................................................................
# set up: wd, retrieve encrypted data
rm(list=ls())
getwd()
# if need be setwd("~/../../")
setwd("R/ShiftResearchLab2018/data-commute")
# set up: libraries
library(dplyr)
library(forcats)
library(tidyverse)
library(readxl)
library(tidyr)
# ..................................................................................................
# AVERAGE COMMUTE TIME
# read in the average commute time data (ACS 2016)
avg <- read_csv("avg.commute.csv")
# select just the first row
avg <- avg[1,]
# move columns to rows
avg <- gather(avg, tract, avgcommute, 2:ncol(avg))
avg <- select(avg, -X1)
# ..................................................................................................
# TRAVEL TIME DISTRIBUTIONS
# read in commute distributions (ACS 2016)
travel <- read_csv("traveltime.csv")
travel <- travel[1:10,] # select rows with values
# reshape the data to be useful
travel <- gather(travel, tract, n, 2:ncol(travel))
travel <- spread(travel, X1, n)
# rename the variables for ease of use
names(travel)
names(travel) <- c("tract", "10to19", "20to29", "30to39", "40to59",
"60to89", "90plus", "total_outside", "less10",
"workedhome", "total")
# reorder the columns
travel <- select(travel, tract, less10, everything())
# merge the data
commute <- left_join(travel, avg, by="tract")
# read in the tract information
info <- read_csv("acs.meta.csv")
info <- select(info, Geo_FIPS, Geo_NAME, Geo_TRACT)
names(info) <- c("geo_id", "tract", "tract_num")
# merge with commute info
commute <- left_join(info, commute, by="tract")
# ..................................................................................................
# MATCHING TRACTS TO NEIGHBORHOODS
# read in matching tracts data
match <- read_csv("matchingtracts.csv")
match <- rename(match, "geo_id"="geoid10")
# merge with commute data
nbhd <- full_join(match, commute, by="geo_id")
# break up the big tract variable
nbhd <- separate(nbhd, tract, c("tract", "county", "state"), sep = ",")
nbhd <- select(nbhd, -c(tract, state))
n_distinct(nbhd$nhid) # 265
n_distinct(nbhd$nhname) # 264 # why is this one less?
# n occurences of each neighborhood name
nhname.freq <- nbhd %>%
count(nhname) # 576 NAs, tracts that don't match a neighborhood
# n occurences of each neighborhood id
nhid.freq <- nbhd %>%
count(nhid) # 576 NAs, tracts that don't match a neighborhood
arb <- filter(nbhd, is.na(nhname)&!is.na(nhid)) # no values so nhname is not blank
str(nbhd) # check the class of the variables
nbhd$avgcommute <- as.numeric(nbhd$avgcommute) # coerce avg commute to numeric class
nbhd$nhid <- as.numeric(nbhd$nhid)
# what's the average denver metro commute time?
mean(nbhd$avgcommute, na.rm=TRUE) # 26.57
median(nbhd$avgcommute, na.rm = TRUE) # 26
# compute neighborhood average commute time
nbhd.avg <- aggregate(nbhd$avgcommute,by=list(name=nbhd$nhname, nhid=nbhd$nhid), data=nbhd, FUN=mean)
nbhd.avg <- rename(nbhd.avg, "avgcommute"="x")
nrow(nbhd.avg) # 264
# 7 NA values, why?
na.check <- filter(nbhd.avg, is.na(avgcommute))
# check with NAs in avg commute removed
nbhd2 <- filter(nbhd, !is.na(nbhd$avgcommute)) # remove observations with NA in avg commute
nbhd.avg2 <- aggregate(nbhd2$avgcommute,by=list(name=nbhd2$nhname, nhid=nbhd2$nhid), data=nbhd2, FUN=mean)
nbhd.avg2 <- rename(nbhd.avg2, "avgcommute"="x")
nrow(nbhd.avg2) # 262 # 2 missing
# check which two are missing
arb <- anti_join(nbhd.avg, nbhd.avg2, by="name")
# Federal Center # Rocky Mountain Arsenal
# one tract each with a missing avg commute and missing travel time, will be excluded
# rename for ease of use
avgcmt <- nbhd.avg2
# number of distinct neighborhoods
n_distinct(avgcmt$name) # 261
# ..................................................................................................
# ADD SOME POTENTIALLY USEFUL MEASURES
mean(avgcmt$avgcommute) # 26.47
avgcmt <- mutate(avgcmt, # difference between nbhd and avg
meandelta=avgcommute-mean(avgcmt$avgcommute))
# ..................................................................................................
# write the object as a csv for later use
write.csv(nbhd, "clean.nbhdcommutes.csv")
write.csv(avgcmt, "clean.avgcommute.csv")
rm(list = ls(pattern = "arb"))
rm(list = ls(pattern = "commute"))
rm(list = ls(pattern = "info"))
rm(list = ls(pattern = "match"))
rm(list = ls(pattern = "nbhd"))
rm(list = ls(pattern = "nh"))
rm(list = ls(pattern = "travel"))
rm(list = ls(pattern = "na.check"))
save.image("commute.Rdata")
# ..................................................................................................
# TO DO LIST:
# figure out why there are 265 nhids and 264 nhnames
